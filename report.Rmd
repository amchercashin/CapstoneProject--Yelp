---
title: "Restaurant busyness attributes effects on business star rating"
author: "Alexandr Cherkashin"
date: "11.11.2015"
output: pdf_document
---

```{r data loading and munging, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
library(jsonlite)
library(caret)

# Reading data----
business <- readRDS("./data/businessRDS")
restaurants <- sapply(business$categories, function(x) "Restaurants" %in% x)
restaurants <- flatten(business[restaurants,])

#DATA MUNGING
# Convinient column names----
colnames(restaurants) <- make.names(colnames(restaurants))

#Noise level attribute to integer level----
noise_level <- restaurants$attributes.Noise.Level
noise_level[noise_level == "quiet"] <- 0
noise_level[noise_level == "average"] <- 1
noise_level[noise_level == "loud"] <- 2
noise_level[noise_level == "very_loud"] <- 3
noise_level <- as.integer(noise_level)

#Parking to three categories: free, paid, no ----
parkingCols <- grep("Parking", colnames(restaurants), value = TRUE)
restaurants[,parkingCols][is.na(restaurants[,parkingCols])] <- "n_a"
parking <- ifelse(restaurants$attributes.Parking.garage == "FALSE" &
                           restaurants$attributes.Parking.validated == "FALSE" &
                           restaurants$attributes.Parking.lot == "FALSE" &
                           restaurants$attributes.Parking.valet == "FALSE" &
                           restaurants$attributes.Parking.street == "FALSE", "no", 
                           ifelse(restaurants$attributes.Parking.garage == "TRUE" |
                                  restaurants$attributes.Parking.validated == "TRUE" |
                                  restaurants$attributes.Parking.lot == "TRUE" |
                                  restaurants$attributes.Parking.valet == "TRUE", "yes", 
                                  ifelse(restaurants$attributes.Parking.street == "TRUE", "street", NA)))
parking <- factor(parking, levels = c("no", "yes", "street"))

#Flatten Accepts credit cars attribute----
credit_cards <- ifelse(sapply(restaurants$attributes.Accepts.Credit.Cards, length) == 0, NA, 
                                                      unlist(restaurants$attributes.Accepts.Credit.Cards))

#Dealing with categories vars----
cat2 <- sapply(restaurants$categories, function(x) {
        if (sum(x=="Afghan")>0|sum(x=="African")>0|sum(x=="Asian Fusion")>0|sum(x=="Bangladeshi")>0|sum(x=="Basque")>0|
            sum(x=="Bavarian")>0|sum(x=="Belgian")>0|sum(x=="British")>0|sum(x=="aCajun/Creole")>0|sum(x=="Cambodian")>0|
            sum(x=="Cantonese")>0|sum(x=="Cuban")>0|sum(x=="Egyptian")>0|sum(x=="Ethiopian")>0|sum(x=="French")>0|
            sum(x=="German")>0|sum(x=="Greek")>0|sum(x=="Hawaiian")>0|sum(x=="Himalayan/Nepalese")>0|sum(x=="Hungarian")>0|
            sum(x=="Indian")>0|sum(x=="Indonesian")>0|sum(x=="Irish")>0|sum(x=="Italian")>0|sum(x=="Japanese")>0|
            sum(x=="Korean")>0|sum(x=="Latin American")>0|sum(x=="Lebanese")>0|sum(x=="Malaysian")>0|sum(x=="Mediterranean")>0|
            sum(x=="Arabian")>0|sum(x=="Argentine")>0|sum(x=="Australian")>0|sum(x=="Brazilian")>0|sum(x=="Caribbean")>0|
            sum(x=="Arabian")>0|sum(x=="Argentine")>0|sum(x=="Australian")>0|sum(x=="Brazilian")>0|sum(x=="Caribbean")>0|
            sum(x=="Chinese")>0|sum(x=="Colombian")>0|sum(x=="Czech")>0|sum(x=="Eastern European")>0|sum(x=="Eastern German")>0|
            sum(x=="Ethnic Food")>0|sum(x=="Filipino")>0|sum(x=="Czech")>0|sum(x=="Haitian")>0|sum(x=="Iberian")>0|
            sum(x=="Laotian")>0|sum(x=="Middle Eastern")>0|sum(x=="Modern European")>0|sum(x=="Mongolian")>0|sum(x=="Moroccan")>0|
            sum(x=="Oriental")>0|sum(x=="Pakistani")>0|sum(x=="Persian/Iranian")>0|sum(x=="Peruvian")>0|sum(x=="Polish")>0|
            sum(x=="Portuguese")>0|sum(x=="Russian")>0|sum(x=="Scandinavian")>0|sum(x=="Scottish")>0|sum(x=="Shanghainese")>0|
            sum(x=="Singaporean")>0|sum(x=="Southern")>0|sum(x=="Spanish")>0|sum(x=="Szechuan")>0|sum(x=="Taiwanese")>0|
            sum(x=="Thai")>0|sum(x=="Trinidadian")>0|sum(x=="Turkish")>0|sum(x=="Ukrainian")>0|sum(x=="Uzbek")>0|
            sum(x=="Venezuelan")>0|sum(x=="Vietnamese")>0|sum(x=="Turkish")>0|sum(x=="Ukrainian")>0|sum(x=="Uzbek")>0) {
                "ThemedOther"}
        else {if(sum(x=="American (New)")>0|sum(x=="American (Traditional)")>0) {"ThemedAmerican"}
                else {if (sum(x=="Mexican")>0|sum(x=="Tex-Mex")>0) {"ThemedOther"}
                        else "NotThemed"}
                }
})

cat1 <- sapply(restaurants$categories, function(x) {
        if (sum(x=="Buffets")>0) "Buffets"
        else if(sum(x=="Fast Food")>0|sum(x=="Chicken Wings")>0|sum(x=="Burgers")>0|sum(x=="Pizza")>0) "Fast Food"
                #else if (sum(x=="Restaurants")>0) "Restaurants"
                        #else if (sum(x=="Bars")>0|sum(x=="Pubs")>0|sum(x=="Irish Pub")>0) "Bars"
                                else if (sum(x=="Cafes")>0) "Cafes"
                                        else "OtherRestaurants"
        
})
cat1 <- factor(cat1, levels = c("Cafes","OtherRestaurants", "Fast Food", "Buffets"))

#Geographocals points----
library(ggmap)
cities<-c('Edinburgh, UK', 'Karlsruhe, Germany', 'Montreal, Canada', 'Waterloo, Canada', 
          'Pittsburgh, PA', 'Charlotte, NC', 'Urbana-Champaign, IL', 'Phoenix, AZ', 'Las Vegas, NV', 'Madison, WI')
city_centres<-geocode(cities)
geo_cluster<-kmeans(restaurants[,c('longitude','latitude')],city_centres)
city2<- factor(geo_cluster$cluster, levels=1:10, labels = cities)
region <- ifelse(geo_cluster$cluster<=2, "Europe", ifelse(geo_cluster$cluster<=4, "Canada", "USA"))
region <- factor(region, levels = c("Europe", "Canada", "USA"))
rm(cities, city_centres, city2, geo_cluster, parkingCols)
alco <- factor(ifelse(restaurants$attributes.Alcohol=="none", "NO", "YES"), levels = c("NO", "YES"))

comp_cases <- complete.cases(data.frame(region, cat1, cat2, restaurants$attributes.Outdoor.Seating, parking, alco,
                                   restaurants$attributes.Price.Range, noise_level))
```

# Introduction

This report provides an attempt to find some objective restaurant characteristics which affects business star rating. There is no goal of building comprehensive predictive model. Instead there is an attempt to identify meaningful attributes that busyness of type "restaurants" could deal with to improve their star rating on Yelp. Understanding what is important to customers is crucial for running business and we hope this report could help.

# Methods and Data

### Data
In analysis we will use Yelp business dataset. This dataset contains `star` variable that is an averaged business star rating from 1 to 5 star rounded to half of a star. It will be our response variable. As we interested in businesses with type "restaurant" we'll take into analysis only observations with string "Restaurants" in `categories` variable.

In addition dataset contain several busyness characteristics some of them we will use as predictors. There are different kinds of variables. Some of them we will transform:

1. From latitude and longitude we'll generate `region` variable which can take three different values: "USA", "Canada", "Europe".
2. `attributes.Noise.Level` will be encoded into integer,  from "quiet" to "very_loud" into `0:3`, and stored in `noise_level` var.
3. Attributes related to *parking* we will transform to `parking` variable with 3 different values: "no"" if there is no parking available, "yes" if there are some parking option except it is not parking street, "street" if there is parking street there.
4. From `categories` var there would be an attempt to make var with some sort of geographic theme or cuisine: `ThemedAmerican`, `ThemedOther` - all other regional themes, and `NotThemed`.
5. Another attempt of categorization based on `categories` variable would be type of restaurant business: `Buffets`, `Fast Food`, `Bars`, `Cafes`, `Other`.
6. `attributes.Alcohol` we'll simplify to two level factor: `YES` - if there is some, otherwise - `NO` and store it in `alco` variable.

Other variables will be taken from dataset without transformation.

There are some variables which contains "Good.For" or "Ambiance" substrings in their names. Such vars appears a little vague on what they mean and how they were measured. In this report we will not take them into analysis, concentrating on more clear some.

There will be no attempts to impute missing values. Only `complete.cases` will be taken.

For the details about feature engineering and other data preparation steps please refer to R code in "report.Rmd"" file at: [https://github.com/amchercashin/CapstoneProject--Yelp/tree/business-analisys](https://github.com/amchercashin/CapstoneProject--Yelp/tree/business-analisys)

### Methods

There was some hesitation on what model to choose. Actually, our response: `stars`, which was measured in halves of a star from 0 to 5, could be interpreted as an ordered factor variable. It has an ordered nature for sure, it is an averaged users star rating rounded to half of a star. And there is no guarantee that the "distances" between star halves are same despite their location. So models like [ordered logit](https://web.stanford.edu/~hastie/Papers/ordered.pdf) or [ordered probit](http://web.stanford.edu/class/polisci203/ordered.pdf) could make sense.

But after all considerations choice was made in favor of linear model. The main point is that the goal of this work is not to build a good predictive model. Instead, we'd like to find what affects star rating most and try to infer the effect and *interpret* it. So the interpretability is has the most value. And linear model is really easier to interpret. So we'll use linear models and refer to `star` variable like it is a real number.

# Results

With variables which left after data preparation and feature engineering the process of variable choosing started. The process in fact was manual. Tries and errors. So the is not much sense describing the full path here. 

After all the linear model was built, let's look at model overall characteristics:
```{r model, echo=FALSE}
s <- summary(lm(formula = stars ~ region + cat1 + cat2 + attributes.Outdoor.Seating + parking + alco + 
                   cat1:alco + parking:alco + I(attributes.Price.Range^4) + I(noise_level^2), 
           data = restaurants, subset = comp_cases))

my_print <- function (x, digits = max(3L, getOption("digits") - 3L), symbolic.cor = x$symbolic.cor, 
    signif.stars = getOption("show.signif.stars"), ...) 
{
    cat("\nCall:\n", paste(deparse(x$call), sep = "\n", collapse = "\n"), 
        "\n\n", sep = "")
    resid <- x$residuals
    df <- x$df
    rdf <- df[2L]
    cat(if (!is.null(x$weights) && diff(range(x$weights))) 
        "Weighted ", "Residuals:\n", sep = "")
    if (rdf > 5L) {
        nam <- c("Min", "1Q", "Median", "3Q", "Max")
        rq <- if (length(dim(resid)) == 2L) 
            structure(apply(t(resid), 1L, quantile), dimnames = list(nam, 
                dimnames(resid)[[2L]]))
        else {
            zz <- zapsmall(quantile(resid), digits + 1L)
            structure(zz, names = nam)
        }
        print(rq, digits = digits, ...)
    }
    else if (rdf > 0L) {
        print(resid, digits = digits, ...)
    }
    else {
        cat("ALL", df[1L], "residuals are 0: no residual degrees of freedom!")
        cat("\n")
    }
    if (length(x$aliased) == 0L) {
        cat("\nNo Coefficients\n")
    }

    cat("\nResidual standard error:", format(signif(x$sigma, 
        digits)), "on", rdf, "degrees of freedom")
    cat("\n")
    if (nzchar(mess <- naprint(x$na.action))) 
        cat("  (", mess, ")\n", sep = "")
    if (!is.null(x$fstatistic)) {
        cat("Multiple R-squared: ", formatC(x$r.squared, digits = digits))
        cat(",\tAdjusted R-squared: ", formatC(x$adj.r.squared, 
            digits = digits), "\nF-statistic:", formatC(x$fstatistic[1L], 
            digits = digits), "on", x$fstatistic[2L], "and", 
            x$fstatistic[3L], "DF,  p-value:", format.pval(pf(x$fstatistic[1L], 
                x$fstatistic[2L], x$fstatistic[3L], lower.tail = FALSE), 
                digits = digits))
        cat("\n")
    }
    correl <- x$correlation
    if (!is.null(correl)) {
        p <- NCOL(correl)
        if (p > 1L) {
            cat("\nCorrelation of Coefficients:\n")
            if (is.logical(symbolic.cor) && symbolic.cor) {
                print(symnum(correl, abbr.colnames = NULL))
            }
            else {
                correl <- format(round(correl, 2), nsmall = 2, 
                  digits = digits)
                correl[!lower.tri(correl)] <- ""
                print(correl[-1, -p, drop = FALSE], quote = FALSE)
            }
        }
    }
    cat("\n")
    invisible(x)
}

my_print(s)
```


And then the coefficients table:
```{r print coefs, echo = FALSE}
knitr::kable(s$coefficients, caption = "Table 1: coefficients from linear model")
```

The impact of variables which are absent in table 1 was considered both small and not very sustainable. 

Let's look at the coefficients closer. The *intercept* - the baseline - is an Cafe in Europe without alcohol, with no regional theme, without outdoor seating and without any parking option.

We see that there are different intercepts of star rating for different regions and different categories of restaurants. There is a tendency to rate restaurants higher in Europe, in Canada mean rating is smaller by 0.17 of a star and in USA even less by next 0.12. What is interesting that it is such a negative effect of being fast food or buffet *exept* if you are offering alcohol there! But as for cafes alcohol is a bad idea and for other restaurants it is OK.

Parking usually gives significant boost to score, especially if there is a parking street. But.. the effect shrinks by half if you offer alcohol at place which sounds reasonable.

There is a tendency to rate restaurants with American theme little less then other. The effect is small, but nevertheless. Outdoor seatings gives a little plus to overall rating.

It is interesting how noise level affects rating. It looks like that negative effect of increasing noise is accelerative in nature: every next level of loudness gives more and more negative effect on rating. From different approximations we choose a one simple: quadratic.

```{r anova, echo=FALSE}
anova(lm(formula = stars ~ I(noise_level), data = restaurants, subset = comp_cases), lm(formula = stars ~ I(noise_level^2), data = restaurants, subset = comp_cases), lm(formula = stars ~ I(noise_level^3), data = restaurants, subset = comp_cases), lm(formula = stars ~ I(noise_level^4), data = restaurants, subset = comp_cases), lm(formula = stars ~ exp(noise_level), data = restaurants, subset = comp_cases))
```

It is better then other simple functions and easier to interpret than a large polynome.

So it looks like that people tolerance to the noise is falling rapidly. There is a half of a star between "quite" and "very_loud" levels: 3 ^ 2 * 0.0543 = 0.49, and most of it is between very loud and average levels. If you have a very loud environment you can gain 0.27 of a star going one step towards quite to the "loud" level. And 0.16 more going one step further to the "average". We have found no correlation with other available variables, but really there could be some with different types of restaurants. And another important question is how noise levels was measured, unfortunately we don't know it.

There is a small but sustainable positive effect of price range. It is non linear too, but still it is small.

# Discussion

First of all, an adjusted R-squared of presented model is 0.1208. So the model describes only 12% of variance in restaurant ratings. And this is understandable: surely every restaurant is different and there are much more important things like quality of food, quality of service, good location spots and others which really should describe the rest.

Certainly there are numerous variable interaction possibilities which are hard to explore. One of the main conclusions that we draw from this analysis was that it is better to concentrate on even more narrow theme. For an example like exploring only one narrow type of restaurant in specific city. And if you succeed you can compare you results to other types or cities. Also it looks like that such separate analysis could have more real value for busyness owners.

There was some simplifications in feature design. The main reason was to decrease feature space for better interpretability. That was the price for choosing a broad question. `cat2` variable is an example: surely it should be more specific. Typology based on `categories` original variable is a deep question by itself.

Another point: there are some doubts about several variables. Actually it could be that price range variable with combinations for an example with alcohol and categories or outdoor seatings - all are signs of some hidden "type of restaurant" variable. Really good typology of businesses is both hard vary valuable.

But despite all this we already have some objective, impersonal and measurable factors which could also affect rating. Knowing them could help in running busyness or help to decide which type of it where should be opened.
